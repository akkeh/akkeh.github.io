<!DOCTYPE html>
<html>
<head>
	<link rel="stylesheet" type="text/css" href="style.css">
	<title>Blog</title>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <style>
        body { counter-reset: h3counter; }
        h2 { 
            margin:1; 
            margin-bottom:0;
            counter-reset: h3counter; 
        }
        h3:before {
            content: counter(h3counter) ".\0000a0";
            counter-increment: h3counter;
        }
        h3 {
            margin-bottom:0;
            counter-reset: h4counter;
        }
        h4:before {
            content: counter(h3counter) "." counter(h4counter) ".\0000a0";
            counter-increment: h4counter;
        }
        h4 {
            margin-bottom:0;
        }
    </style>
</head>
<body onload="loadMenu()">
	<header>
		<h1>/blog</h1>
	</header>
	<nav id="menu"><!-- gets populated by body.onload() --> </nav>
    <main>
        <h2 style="margin:1; margin-bottom:0"><span style="font-weight:normal"></span>Introduction</h2>

        <p>A collection of short essays about several topics that interest me. I write about my main interest: theoretical neuroscience, and its connection to other topics such as philosophy. biotechnology, biology, society, computers and politics. Besides that I will include short snippets of code and small 'tutorials' on techniques that interest me.
        </p>
        <hr style="height:1px;background-color:black"><br><br>
        <h2><span style="font-weight:normal">20200915</span> First-passage-time distribution of leaky IF neuron</h2>
        <i>First-passage-time; Inter-spike-interval; leaky IF neuron</i>
        <p>
            Historically the rate of firing of neurons has been used as the primary measure for the functioning of neurons. Especially with the possibility to record the activity of single neurons many studies have been carried out to quantify the rate of firing of single neurons in response to particular stimuli. However neurons are 'noisy', and so these experiments typically result in a distribution of inter-spike times, called 'inter-spike-interval histogram', of a neuron. 
        </p>
        <p>
            A widely used model of a single neuron is the leaky integrate-and-fire neuron, originally introduced by Lapicque in 1907. This abstract model consists of a description of the evolution of a membrane voltage \(v\) of a neuron, driven by an input \(I\):
                $$ \tau \frac{dv}{dt} = I(t)-v(t). \tag{1} $$
            The parameter \(\tau\) is the membrane time-constant and determines how fast the membrane potential follows changes in steady state inputs, and how fast the potential decays back to its steady state after a perturbation. 
            The second component of the leaky integrate-and-fire neuron is a spike-and-reset rule: if the potential reaches a threshold value \(v \leq v_c\) it is reset to a value \(v_r < v_c\), whereafter its evolution is again governed by <a href="#mjx-eqn-1">(1)</a>. The firing rate of the leaky integrate-and-fire neuron can thus be determined from the time it takes between consecutive spike-and-resets. In this post I will look at the expression of the inter-spike-interval distribution of the leaky integrate-and-fire neuron.
        </p>
        <h3>Deterministic constant input</h3>
        <p style="margin-top:0">
        	For constant inputs \(I(t) = \bar{I}\), the membrane potential shows an exponential approach to the value \( v_\infty = \bar{I} \). In the case of a constant supra-threshold input \( \bar{I}>v_c \) it is straightforward to calculate the firing rate of the model neuron:
		$$ T_{isi} = -\tau ln\left(\frac{v_c-\bar{I}}{v_r-\bar{I}}\right). $$
        </p> 
        <h3>Stochastic input</h3>
        <p style="margin-top:0">
        	However, as stated before, neurons are generally considered to be noisy. This noisiness can be captured by considering an input
        		$$ I(t) = \mu + \sigma \eta(t), $$
	        in which \(\mu\) is a constant (mean) input, and \(\eta(t)\) is a fluctuating noise input. With this input <a href="#mjx-eqn-1">(1)</a> becomes a stochastic differential equation (SDE). A classical problem is to describe the first-passage-time (FTP) distribution, the distribution of the times that it takes for such a process to cross a threshold value, of SDEs. In the case that the noise part of the input is taken to be a gaussian white noise \(\eta(t) = dW_t\), the membrane potential follows an <a href="en.wikipedia.org/wiki/Ornstein-Uhlenbeck_process">Ornstein-Uhlenbeck process</a> (Uhlenbeck & Ornstein, 1930; Ricciardi & Sacerdote, 1979). The exact description of the first-passage-time distribution (the 'first-passage-time problem') of Ornstein-Uhlenbeck type processes is, however, still an unsolved problem.
    	</p>
        <p>
            It will thus in general not be possible to obtain an exact expression for the first-passage-time distribution of the leaky integrate-and-fire neuron. 
            Gerstein and Mandelbrot (1964) considered the first-passage-time distribution of the perfect integrate-and-fire neuron, which is equal to the leaky integrate-and-fire neuron, but without the exponential drive back to a resting potential (i.e. <a href="#mjx-eqn-1">(1)</a> without the \(-v\) term on the r.h.s.). In this case the membrane potential describes a (biased) Brownian motion, for which exact descriptions of the first-passage-time distribution are known.
        </p>
        <p>
        However, an important characteristic of neuronal membrane potentials is the relaxation to a resting potential in absence of input (Gluss, 1967). Steps have been made towards the expression of the first-passage-time distribution of the leaky integrate-and-fire neuron. Exact expression exist for restricted sets of parameters (Siebert, 1969; Sugiyama, Moore & Perkel, 1970), in Laplace transformed form (Roy & Smith, 1969; Sugiyama, Moore & Perkel, 1970, Capocelli & Ricciardi, 1971), as well as by approximation (Swalger & Schimansky-Geier, 2008).
        </p>
        <h3 style="margin-bottom:0">A naive and an-exact FPT distribution</h3>
        <p style="margin-top:0">
        Here however, I would like to present a naive approach to an an-exact expression of the first-passage-time distribution which agrees surprisingly well with numerical simulations. This expression will be exact in the case that the reset potential is the additive inverse of the mean input: \(v_r = -\mu\). Considering a neuron driven by a specifically coloured noise, depending on the membrane time-constant \(\tau\):
            $$ \eta(t) = W(t) + \tau dW_t, $$
            where \(W(t) = \int_0^t dW_t\).
        Defining \(k = \tau^{-1}\) for notational convenience, equation <a href="#mjx-eqn-1">(1)</a> becomes:
            $$ dv = k(\mu-v) dt + \sigma ( kW dt + dW_t). \tag{3}$$

        Shifting the membrane potential in order to remove the \(\mu\) term (thus \(x := v-\mu\), \(x_c := v_c-\mu\) & \(x_r := v_r-\mu\), and Laplace transforming <a href="#mjx-eqn-3">(3)</a> leads to:
            $$ (k+s)\widetilde{x} = \sigma (k+s)\widetilde{W} + x(0). $$
        Dividing both sides by \((k+s)\), applying the inverse Laplace transform, and differentiating gives:
            $$ dx = \sigma dW_t - kx(0) e^{-kt} dt, $$
        which describes a Brownian motion (perfect integrate-and-fire neuron) with an exponential driving. Since the leaky integrate-and-fire neuron gets completely reset after a spike occurs and we are interested in the inter-spike interval distribution we can set \(x(0) = x_r\).
        </p>
        <h4>Natural diffusion</h4>
        <p style="margin-top:0">
            The evolution of the probability density of the membrane potential \(P(x,t)\) is described by the Fokker-Planck equation
                $$ \frac{\partial P}{\partial t} = kx_r e^{-kt} \frac{\partial P}{\partial x} + \frac{\sigma^2}{2}\frac{\partial^2 P}{\partial x^2}, \tag{4} $$
            with the initial condition \(P(x,0) = \delta(x-x_r) \) and Dirichlet boundary \(P(x_c, t) = 0\).
            By disregarding for the moment the spike-and-reset mechanism (or equivalently setting \(x_c = \infty\)) we can solve for \(P\):
                $$ P(x,t) = \frac{1}{\sqrt{2\pi\sigma^2t}} \exp{\left[ -\frac{(x-x_re^{-kt})^2}{2\sigma^2t}\right]}, $$
            finding that \(P(x,t)\) is a Gaussian with time-dependent variance \(\sigma^2t\) and mean \(x_re^{-kt}\).
            Unfortunately, when enforcing the spike-and-reset mechanism (i.e. \(x_c < \infty)\), no solution has (so far) been found for general cases.
        </p>
        <h4>Perfect IF neuron</h4>
        <p style="margin-top:0">
            For the perfect integrate-and-fire neuron the Fokker-Planck equation <a href="#mjx-eqn-4">(4)</a> does not have the drift term \(kx_re^{-kt}\frac{\partial P}{\partial x}\), and thus has a natural solution
                $$ P(x,t) = \frac{1}{\sqrt{2\pi\sigma^2t}}exp{\left[-\frac{(x-x_r)^2}{2\sigma^2t}  \right]}. $$
            The absence of the time-dependent mean makes it possible to construct a solution with the boundary \(P(x_c,t)=0\) by using the method of images
                $$ P_c(x,t) = \frac{1}{\sqrt{2\pi\sigma^2t}}\left(exp{\left[-\frac{(x-x_r)^2}{2\sigma^2t}\right]} - exp{\left[-\frac{(x-2x_c+x_r)^2}{2\sigma^2t}\right]}  \right), \tag{5}$$
            thus a solution by the superposition of the natural solution and a virtual 'sink' outside the considered domain \([\infty, x_c)\). This solution can be verified by checking that \(P_c(x,t)\rvert_{x=x_c}\) = 0, \(P_c(x,t)\rvert_{t=0}=\delta(x-x_r)\) and that \(P_c\) solves the Fokker-Planck equation <a href="#mjx-eqn-4">(4)</a>.
        </p>
        <h4>Return to the leaky IF neuron</h4>
        <p style="margin-top:0">
            Naively, one would try to apply the method of images also to solve <a href="#mjx-eqn-4">(4)</a>, trying to equivalently to subtract a mirror distribution with an inverted mean:
                $$ \hat{P}_c(x,t) = \frac{1}{\sqrt{2\pi\sigma^2t}}\left( \exp{\left[ -\frac{(x-x_re^{-kt})^2}{2\sigma^2t}\right]} - \exp{\left[ -\frac{(x-2xc+x_re^{-kt})^2}{2\sigma^2t}\right]} \right), \tag{6}$$
        which complies with \(\hat{P}_c(x,t)\rvert_{x=xc}=0\) and \(\hat{P}_c(x,t)\rvert_{t=0}=\delta(x-x_r)\), for \(x < x_c\). But crucially (in general) does <i>not</i> solve the Fokker-Planck equation <a href="#mjx-eqn-4">(4)</a>. In section <a href="#exact_cases">Special cases with exact expressions</a> I list some cases in which <a href="#mjx-eqn-6">(6)</a> <i>is</i> an exact solution.
        </p>
        <h4>FTP distribution</h4>
        <p style="margin-top:0">
            Continuing naively with the membrane voltage distribution of <a href="#mjx-eqn-6">(6)</a>, by integrating over possible values of \(x\) we find the probability distribution that at time \(t\) a neuron has not yet fired:
                $$
                    S(t)    =  \int_{-\infty}^{x_c}\hat{P}_c(x,t)dx
                            =  -erf\left(-\frac{x_c-x_re^{-kt}}{\sqrt{2\sigma^2t}}\right), \tag{7}
                $$
            then \(1-S(t)\) is the probability that a neuron has fired some time before \(t\). Changes in \(1-S(t)\) with respect to time then relate to the probability of the timings of threshold crossings. The first-passage-time distribution is then the time-derivative of \(1-S(t)\):
                $$ f(t) = \frac{\partial}{\partial t} \left[1-S(t)\right] = \left[ \frac{\lvert x_c-x_re^{-kt}\rvert}{\sqrt{2\pi\sigma^2t^3}} - \frac{2kx_re^{-kt}}{\sqrt{2\pi\sigma^2t}} \right] exp\left(-\frac{(x_c-x_re^{-kt})^2}{2\sigma^2t}\right). \tag{8} $$
            Thus the first-passage-time distribution is the superposition of a <a href="en.wikipedia.org/wiki/Lévy_distribution">L&eacute;vy distribution</a> with the product of a decaying exponential and a gaussian.
        </p>
        <p>
            The following figure shows the first-passage-time distribution and measured histograms for several different values of \(k=\tau^{-1}\), for \(x_r=-3\) and \(x_c = 1\).
            <figure>
                <img src="fpt.jpg" alt="fpt_image" style="max-width:100%;max-height:100vh;margin:auto">
                <figcaption>Fig.01: <b>First-passage-time distributions and histograms</b> for several values of \(k=\tau^{-1}\). The remaining parameters are \(x_r=-3\) and \(x_c=1\). The measured histograms are the result of numerical simulation of \(1e4\) neurons carried out untill \(1e6\) time-steps</figcaption>
            </figure>
        </p>
        
<!---
        <h3 id="exact_cases">Special cases with exact expressions</h3>
        <p style="margin-top:0">
            There are some cases in which <a href="#mjx-eqn-6">(6)</a> is an exact solution to the Fokker-Planck equation. In this section I list two.
            <h4 style="margin-bottom:0">Perfect IF \(x_r=-\mu\)</h4>
            <p style="margin-top:0">
                This case was already alluded to in the introduction. Clearly, in case \(x_r = 0\) (thus \(v_r=-\mu\)), the evolution of the membrane potential distribution of the leaky integrate-and-fire neuron <a href="#mjx-eqn-6">(6)</a> is equal to that of the perfect integrate-and-fire neuron <a href="#mjx-eqn-5">(5)</a>, and thus in this case <a href="#mjx-eqn-6">(6)</a> is an exact solution to the Fokker-Planck equation <a href="#mjx-eqn-4">(4)</a>.
            </p>
            <p>
                The first-passage-time distribution is then given by
                $$ f(t) = \frac{\lvert x_c \rvert}{\sqrt{2\pi\sigma^2t}}\exp{\left[-\frac{x_c^2}{2\sigma^2t}\right]}. $$
            <figure>
                <img src="pIFfpt.jpg" alt="pIFfpt_image" style="max-width:100%;max-height:100vh;margin:auto">
                <figcaption>Fig.02: <b>First-passage-time distributions and histograms</b> for the perfect integrate-and-fire neuron (equivalently for the leaky integrate-and-fire neuron) for \(x_r=-\mu\), for different values of \(k=\tau^{-1}\). The threshold is set at \(x_c=0.2\). The measured histograms are the result of numerical simulation of \(1e4\) neurons carried out untill \(1e6\) time-steps</figcaption>
            </figure>
            </p>
            <h4 style="margin-bottom:0">Reflection around \(x_c=0\)</h4>
            <p style="margin-top:0">
                If we carry out a change of variables \(y:=\lvert x \rvert\) in <a href="#mjx-eqn-4">(4)</a>, the Fokker-Plank equation for the membrane potential density becomes:
                $$ 
                        \frac{\partial P}{\partial t} = \begin{cases}
                            -kx_re^{-kt}\frac{\partial P}{\partial y} + \frac{\sigma^2}{2}\frac{\partial^2 P}{\partial y^2}, & x<0  \\
                            kx_re^{-kt}\frac{\partial P}{\partial y} + \frac{\sigma^2}{2}\frac{\partial^2 P}{\partial y^2}, & x\geq 0, 
                    \end{cases}\tag{9}
                $$
                
                then by setting \(x_c=0\), 
                $$ P(x,t) = \frac{1}{\sqrt{2\pi\sigma^2t}}\left( \Theta(-x) \exp{\left[ -\frac{(\lvert x \rvert+ x_re^{-kt})^2}{2\sigma^2t}\right]} - \Theta(x)\exp{\left[ -\frac{(\lvert x \rvert - x_re^{-kt})^2}{2\sigma^2t}\right]} \right) $$
                solves <a href="#mjx-eqn-9">(9)</a>. Notice that this solution is equivalent to <a href="#mjx-eqn-6">(6)</a>.
            </p>
            <p>
                Integrating over \(x\) leads to the survival probability
                $$ \begin{align} 
                    S(t)    &= \int_{-\infty}^0 P(x,t)dx\\
                            &= \frac{1}{\sqrt{2\pi\sigma^2t}}\left( \int_{-\infty}^0 \exp{\left[ -\frac{-(-x+x_re^{-kt})^2}{2\sigma^2t} \right]}dx - \int_{-\infty}^0\delta(x)\exp{\left[-\frac{(x_re^{-kt})^2}{2\sigma^2t} \right]}dx\right) \\
                            &= \frac{1}{2}-\frac{1}{2}erf\left(\frac{x_re^{-kt}}{\sqrt{2\sigma^2t}}\right) - \frac{1}{\sqrt{2\pi\sigma^2t}}\exp{\left[-\frac{x_r^2e^{-2kt}}{2\sigma^2t} \right]}. \tag{10}
                \end{align}
                $$
            
            </p>
        </p>
        <h3>Steps towards an exact expression</h3>
        <p style="margin-top:0">
            Plugging \(\hat{P}_c\) into <a href="#mjx-eqn-4">(4)</a> leads to the equation
                $$ \frac{\partial \hat{P}_c}{\partial t} - kx_re^{-kt}\frac{\partial \hat{P}_c}{\partial x} - \frac{\sigma^2}{2}\frac{\partial^2 \hat{P}_c}{\partial x^2} = -2\frac{(-x+2x_c-x_re^{-kt})^2}{\sigma^2t}\hat{P}_c. \tag{A1}$$
        </p>
--->
        <h3>References:</h3>
        <ul>
            <li>Capocelli, R.M., & Ricciardi, L.M. (1971). <i>Diffusion approximation and first passage time problem for a model neuron</i>. Kybernetik, 8(6), 214-223.</li>
            <li>Gerstein, G.L., & Mandelbrot, B. (1964). <i>Random walk models for the spike activity of a single neuron.</i> Biophy. j., 4(1), 41-68.</li>
            <li>Gluss, B. (1967). <i>A model for neuron firing with exponential decay of potential resulting in diffusion equations for probability density.</i> Bull. math. biophys., 29(2), 233-243.</li>
            <li> Lapicque, L. (1907). <i>Recherches quantitatives sur l'excitation &eacute;lectrique des nerfs trait&eacute;e comme une polarisation.</i> J. physiol. pathol. gen., 9, 620-635</li>
            <li>Roy, B.K., & Smith, D.R. (1969). <i>Analysis of the exponential decay model of the neuron showing frequency threshold effects</i>. Bull. math. biophys., 31(2), 341-357.</li>
            <li>Schwalger, T., & Schimansky-Geier, L. (2008). <i>Interspike interval statistics of a leaky integrate-and-fire neuron driven by Gaussian noise with large correlation times</i>. Phys. rev. E, 77(3), 031914.</li>
            <li>Siebert, W.M. (1969). <i>On stochastic neural models of the diffusion type</i>. Mass. instit. technol. res. lab. electron. quart. tech. rep, 94, 281-287.</li>
            <li>Sugiyama, H., Moore, G.P., & Perkel, D.H. (1970). <i>Solutions for a stochastic model of neuronal spike production.</i> Math. biosci., 8(3-4), 323-341.</li>



            <!--- <li> Brunel, N., & Van Rossum, M.C. (2007). <i>Lapicque's 1907 paper: from frogs to integrate-and-fire.</i> Biol. cybern., 97(5-6), 337-339. </li> --->
        </ul>
<!---
<h2 style="margin:1; margin-bottom:0"><span style="font-weight:normal">20190404 </span>Materialist introduction
</h2>
<i> Materialism; Neuroscience
</i><br>
<p>
</p>I like materialism. I believe in the creativity of matter and that matters interact forming multiplicities that are more than the sum of their parts. I do not believe that there is any sense in or necessity that being a materialist would 'force' me to think that knowing the state of things and their interactions would allow to calculate the future state of things. Or atleast that a material world would imply this any more than a dualistic worldview. I am completely in the dark as to why the problem of determinism is solved by dualism. I am still in the process of determining what makes it impossible to determine the future state of things. I do not consider the impossibility of knowing the state of all things or the precise interactions from a pure complexity point of view to be a satisfactory explaination. Thus the uncertainty principle brought forth by quantum mechanics, which seems in the end a shortcoming from our side, to be a solution either. Unless one could argue that the way of determining the position and velocity of a particle is fundamental to any interaction with that particle. But this sort of hints at the universe working as a computer which calculates, using the Rules of Physics, how each particle should behave. Which is again not satisfactory (although more of an intuitive objection than a clearly argumentable one).
</p>
</p>Thus I am still investigating what are for me satifactory explainations to this question, but this does not make it impossible to use these materialist monist ideas to theorise about the world, life and the brain. Within the determinism/free will debate the human brain has always figured on center stage, and specific anatomical regions have been singled out to be the seat of consciousness, or the interface between the material and 'other' world. So it is not suprising that within my neuroscience practise I support materialist ideas: I believe that neurons and then brain are material and that all things that we are used from our brains emerge from the interactions of material neurons. Due to the creative nature of matter, this does not lead to boring input-output transformations or conditioned responses, but a plethora of dynamics and the baffeling richness of experience. This is why I study theoretical neuroscience: as I see it, it is the study of what neural systems could do. For me, theoretical neuroscience investigates what our theories and models of neurons are capable of doing. This brings an interesting layering of abstraction and a series of fault introducing translations, which lead to a comforting and pleasing chain of errors. Comforting, because it prevents us from arguing with any certainty that the brain works in this or that manner, and thus does not provide any ground for choosing this over that, opression or governing. It is pleasing, because it always keeps the door open for other possibilities.
</p>
</p>
-->
<hr style="height:1px; background-color:black">
</main>
<script src="menu.js"></script>
</body>
</html>
